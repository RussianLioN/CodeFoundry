# ğŸ“Š Skill: Monitoring

> [ğŸ  Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ](../../../../README.md) â†’ [ğŸ¦ OpenClaw](../../../README.md) â†’ [ğŸ¯ Workspace](../README.md) â†’ [ğŸš€ DevOps Skills](#)

---

## Description

ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ¼ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ¸ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµĞ¼Ğ¾ÑÑ‚Ğ¸.

---

## ğŸ¯ Capabilities

### ğŸ“ˆ Metrics Collection

**Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:**
```
ğŸ‘¤ "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ"
ğŸ‘¤ "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ CPU Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸"
ğŸ‘¤ "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ´Ğ»Ñ API"
```

**Ğ¢Ğ¸Ğ¿Ñ‹ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:**
- **System** â€” CPU, Memory, Disk, Network
- **Application** â€” Request rate, Latency, Error rate
- **Business** â€” Orders per minute, Active users, Revenue
- **Custom** â€” Domain-specific metrics

---

### ğŸ”” Alerting

**Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:**
```
ğŸ‘¤ "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ°Ğ»ĞµÑ€Ñ‚Ñ‹ Ğ½Ğ° Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğµ latency"
ğŸ‘¤ "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ°Ğ»ĞµÑ€Ñ‚ ĞµÑĞ»Ğ¸ Ğ´Ğ¸ÑĞº Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½"
ğŸ‘¤ "ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞ¹ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ² Telegram"
```

**Ğ¢Ğ¸Ğ¿Ñ‹ Ğ°Ğ»ĞµÑ€Ñ‚Ğ¾Ğ²:**
- **Threshold** â€” ĞŸÑ€ĞµĞ²Ñ‹ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
- **Anomaly** â€” ĞĞ½Ğ¾Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ
- **Rate** â€” Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ
- **Composite** â€” Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ

---

### ğŸ“Š Dashboards

**Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:**
```
ğŸ‘¤ "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°"
ğŸ‘¤ "ĞŸĞ¾ĞºĞ°Ğ¶Ğ¸ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸"
ğŸ‘¤ "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² ÑĞµĞºÑƒĞ½Ğ´Ñƒ"
```

**Ğ’Ğ¸Ğ´Ñ‹ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ¾Ğ²:**
- **System Overview** â€” ĞĞ±Ñ‰ĞµĞµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹
- **Application Performance** â€” ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
- **Business Metrics** â€” Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸
- **Incident Response** â€” Ğ”Ğ»Ñ troubleshooting

---

## ğŸ”§ Supported Systems

| Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° | Ğ¢Ğ¸Ğ¿ | ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ |
|---------|-----|-------------|
| **Prometheus** | Metrics | Time series DB,Pull model,Alertmanager |
| **Grafana** | Dashboards | Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ,Ğ°Ğ»ĞµÑ€Ñ‚Ñ‹,plugins |
| **Loki** | Logs | Aggregated logging,Like Prometheus |
| **Tempo** | Tracing | Distributed tracing |
| **ELK Stack** | Logs | Elasticsearch,Logstash,Kibana |
| **Datadog** | APM | SaaS,All-in-one,APM |
| **New Relic** | APM | SaaS,APM,Browser monitoring |
| **CloudWatch** | Metrics | AWS native,Logs,Metrics |

---

## ğŸ“¦ Prometheus Configuration

### prometheus.yml

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'production'
    environment: 'eu-west-1'

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093

# Rule files
rule_files:
  - 'alerts/*.yml'

# Scrape configurations
scrape_configs:
  # Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Node Exporter - system metrics
  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']
    relabel_configs:
      - source_labels: [__address__]
        target_label: instance
        replacement: 'server-01'

  # Application metrics
  - job_name: 'myapp'
    static_configs:
      - targets: ['myapp:3000']
    metrics_path: '/metrics'
    scrape_interval: 10s

  # Kubernetes pods
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
```

---

## ğŸš¨ Alert Rules

### alerts/rules.yml

```yaml
groups:
  - name: system_alerts
    interval: 30s
    rules:
      # High CPU usage
      - alert: HighCPUUsage
        expr: (100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 80
        for: 5m
        labels:
          severity: warning
          team: devops
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 80% for 5 minutes (current: {{ $value }}%)"

      # High memory usage
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 85% (current: {{ $value }}%)"

      # Disk space low
      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 15
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: "Disk space low on {{ $labels.instance }}"
          description: "Disk space is below 15% (current: {{ $value }}%)"

  - name: application_alerts
    interval: 30s
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: (rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])) * 100 > 5
        for: 5m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "High error rate"
          description: "Error rate is above 5% for 5 minutes (current: {{ $value }}%)"

      # High latency
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High latency detected"
          description: "P95 latency is above 1s (current: {{ $value }}s)"

      # Service down
      - alert: ServiceDown
        expr: up{job="myapp"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "Service has been down for 2 minutes"
```

---

## ğŸ¨ Grafana Dashboards

### Dashboard JSON Template

```json
{
  "dashboard": {
    "title": "Application Overview",
    "tags": ["app", "production"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      },
      {
        "id": 2,
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
            "legendFormat": "Errors"
          }
        ]
      },
      {
        "id": 3,
        "title": "P95 Latency",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "P95"
          }
        ]
      }
    ]
  }
}
```

---

## ğŸ“ Application Metrics

### Node.js (Prometheus Client)

```javascript
const promClient = require('prom-client');

// Create registry
const register = new promClient.Registry();

// Default metrics (CPU, memory, etc.)
promClient.collectDefaultMetrics({ register });

// Custom metrics
const httpRequestDuration = new promClient.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status_code'],
  buckets: [0.1, 0.5, 1, 2, 5]
});

const httpRequestsTotal = new promClient.Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'route', 'status']
});

// Middleware
app.use((req, res, next) => {
  const start = Date.now();

  res.on('finish', () => {
    const duration = (Date.now() - start) / 1000;
    httpRequestDuration
      .labels(req.method, req.route?.path || 'unknown', res.statusCode)
      .observe(duration);
    httpRequestsTotal
      .labels(req.method, req.route?.path || 'unknown', res.statusCode)
      .inc();
  });

  next();
});

// Metrics endpoint
app.get('/metrics', async (req, res) => {
  res.set('Content-Type', register.contentType);
  res.end(await register.metrics());
});
```

### Python (FastAPI)

```python
from prometheus_fastapi_instrumentator import Instrumentator
from prometheus_client import Counter, Histogram

# Custom metrics
request_count = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

# Setup
app = FastAPI()

Instrumentator().instrument(app).expose(app)

# Usage in endpoints
@app.get("/api/users")
async def get_users():
    with request_duration.labels('GET', '/api/users').time():
        # Your logic here
        result = await fetch_users()
        request_count.labels('GET', '/api/users', 200).inc()
        return result
```

---

## ğŸ”” Alert Notifications

### Alertmanager Configuration

```yaml
global:
  resolve_timeout: 5m
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
  telegram_api_url: 'https://api.telegram.org/bot{token}/sendMessage'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'

  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
      continue: true

    - match:
        severity: warning
      receiver: 'warning-alerts'

receivers:
  - name: 'default'
    slack_configs:
      - channel: '#alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

  - name: 'critical-alerts'
    slack_configs:
      - channel: '#critical'
    telegram_configs:
      - bot_token: 'YOUR_BOT_TOKEN'
        chat_id: 123456789
        message: 'ğŸš¨ CRITICAL: {{ .GroupLabels.alertname }}'

  - name: 'warning-alerts'
    slack_configs:
      - channel: '#warnings'
```

---

## ğŸ“Š Logging Strategy

### Loki Configuration

```yaml
server:
  http_listen_port: 3100

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://localhost:3100/loki/api/v1/push

scrape_configs:
  - job_name: myapp
    static_configs:
      - targets:
          - localhost
        labels:
          job: myapp
          __path__: /var/log/myapp/*.log

    pipeline_stages:
      - json:
          expressions:
            level: level
            message: message
            timestamp: time

      - labels:
          level:

      - timestamp:
          source: timestamp
          format: RFC3339
```

---

## ğŸ“ Usage Examples

### Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹ 1: Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³

```
ğŸ‘¤ "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ Prometheus + Grafana Ğ´Ğ»Ñ Ğ¼Ğ¾ĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ"

ğŸ¤– Monitoring Skill:
    1. ğŸ“‹ Analysing application stack...
    2. âœ… Detected: Node.js + Express
    3. ğŸ“¦ Creating configs:
       - prometheus.yml (scrape config)
       - alerts/rules.yml (alert rules)
       - grafana/dashboards/app.json (dashboard)
    4. ğŸ³ Adding docker-compose.yml with:
       - prometheus
       - grafana
       - node-exporter
       - alertmanager
    5. âœ… Monitoring stack ready
    6. ğŸŒ Access at: http://localhost:3000 (Grafana)
```

### Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹ 2: ĞĞ»ĞµÑ€Ñ‚Ñ‹

```
ğŸ‘¤ "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ°Ğ»ĞµÑ€Ñ‚Ñ‹ Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºÑƒ Ğ² Telegram"

ğŸ¤– Monitoring Skill:
    1. ğŸ“ Creating alertmanager.yml...
    2. ğŸ“‹ Adding alert rules:
       - Service down (critical)
       - High error rate (critical)
       - High latency (warning)
    3. ğŸ“± Configuring Telegram bot...
    4. âœ… Alerts configured
    5. ğŸ’¬ Test alert sent to verify setup
```

### Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹ 3: Voice Command

```
ğŸ—£ï¸ "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"

ğŸ¤– Monitoring Skill:
    1. ğŸ“‹ Adding database monitoring...
    2. ğŸ“¦ Created configs:
       - postgres_exporter scrape config
       - DB metrics dashboard
       - Alert rules for:
         â€¢ Connection pool exhaustion
         â€¢ Slow queries
         â€¢ Replication lag
    3. âœ… DB monitoring enabled
```

---

## ğŸ”— Integration with Tools

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹:
- **write** â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹
- **read** â€” Ñ‡Ñ‚ĞµĞ½Ğ¸Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº
- **bash** â€” Ğ·Ğ°Ğ¿ÑƒÑĞº ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
- **docker** â€” Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ ÑÑ‚ĞµĞºĞ° Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°

---

## ğŸ”— Voice Commands

| Ğ“Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ°Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° | Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ |
|-------------------|----------|
| "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³" | ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Prometheus + Grafana |
| "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ°Ğ»ĞµÑ€Ñ‚Ñ‹" | Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ alert rules |
| "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´" | Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Grafana dashboard |
| "ĞŸĞ¾ĞºĞ°Ğ¶Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸" | ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº |
| "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ" | ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Loki |

---

## ğŸ›¡ï¸ Best Practices

### 1. USE Method (Utilization, Saturation, Errors)

```yaml
# Utilization - Ğ½Ğ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ€ĞµÑÑƒÑ€Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ
rate(node_cpu_seconds_total{mode!="idle"}[5m])

# Saturation - Ğ½Ğ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ€ĞµÑÑƒÑ€Ñ Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ¶ĞµĞ½
node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes

# Errors - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
rate(http_requests_total{status=~"5.."}[5m])
```

### 2. RED Method (Rate, Errors, Duration)

```yaml
# Rate - Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² ÑĞµĞºÑƒĞ½Ğ´Ñƒ
rate(http_requests_total[5m])

# Errors - Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])

# Duration - latency (P95)
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
```

### 3. Label Cardinality

```yaml
# âŒ ĞŸĞ»Ğ¾Ñ…Ğ¾ - ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ label Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹
http_requests_total{user_id="12345"}

# âœ… Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾ - Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ğµ label Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
http_requests_total{method="GET", status="200", route="/api/users"}
```

---

## ğŸ“š Ğ¡Ğ¼. Ğ¢Ğ°ĞºĞ¶Ğµ

- [ğŸš€ DevOps Skills Index](../README.md)
- [ğŸ³ Docker Deploy](docker-deploy.md)
- [ğŸš€ CI Pipeline](ci-pipeline.md)
- [ğŸ¯ Workspace](../README.md)
- [ğŸ¤– Agents](../AGENTS.md)

---

## ğŸ”„ Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹

| Ğ’ĞµÑ€ÑĞ¸Ñ | Ğ”Ğ°Ñ‚Ğ° | Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ |
|--------|------|-----------|
| 1.0.0 | 2025-11-05 | ĞŸĞµÑ€Ğ²Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ skill |

---

> [ğŸ  Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ](../../../../README.md) â†’ [ğŸ¦ OpenClaw](../../../README.md) â†’ [ğŸ¯ Workspace](../README.md) â†’ [ğŸ“Š Monitoring](#)
