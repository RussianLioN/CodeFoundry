# ğŸ³ OpenClaw Docker Stack

> [ğŸ  Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ](../../README.md) â†’ [ğŸ¦ OpenClaw](../README.md) â†’ [ğŸ³ Docker](#)

---

## ĞĞ±Ğ·Ğ¾Ñ€

ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Docker stack Ğ´Ğ»Ñ OpenClaw Ñ **Ollama** Ğ¸ **gemini-3-flash** Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Docker Stack Architecture                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  openclaw-gateway (Node.js)                            â”‚    â”‚
â”‚  â”‚  â€¢ WebSocket Server :18789                             â”‚    â”‚
â”‚  â”‚  â€¢ Agent Orchestration                                 â”‚    â”‚
â”‚  â”‚  â€¢ Telegram Bot Integration                            â”‚    â”‚
â”‚  â”‚  â€¢ Session Management                                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                         â”‚
â”‚                      â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  ollama-service (AI Runtime)                           â”‚    â”‚
â”‚  â”‚  â€¢ Ollama Server :11434                                â”‚    â”‚
â”‚  â”‚  â€¢ gemini-3-flash model                                â”‚    â”‚
â”‚  â”‚  â€¢ 131K context window                                 â”‚    â”‚
â”‚  â”‚  â€¢ Persistent model storage                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  Volumes:                                                        â”‚
â”‚  â€¢ ollama_models    - Model persistence                         â”‚
â”‚  â€¢ openclaw_logs    - Gateway logs                             â”‚
â”‚  â€¢ workspace/       - CodeFoundry + projects                    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

- Docker Engine 20.10+
- Docker Compose 2.0+
- 8GB RAM Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ (16GB Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)
- 10GB Ğ´Ğ¸ÑĞºĞ¾Ğ²Ğ¾Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ¾ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹

**ĞĞ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ GPU:**
- NVIDIA Docker Runtime
- CUDA 12.0+
- NVIDIA GPU Ñ 8GB+ VRAM

---

## ğŸš€ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ğ¡Ñ‚Ğ°Ñ€Ñ‚

### 1. ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ°

```bash
cd openclaw/docker

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ .env Ñ„Ğ°Ğ¹Ğ»
cat > .env << 'EOF'
# Workspace
WORKSPACE_DIR=./workspace

# Telegram Bot (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
TELEGRAM_BOT_TOKEN=your_token_here
TELEGRAM_WEBHOOK_SECRET=your_secret_here

# Tailscale (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
TS_AUTHKEY=your_tailscale_authkey_here

# Ollama
OLLAMA_BASE_URL=http://ollama-service:11434
OLLAMA_MODEL=gemini-3-flash

# Gateway
GATEWAY_PORT=18789
NODE_ENV=production
EOF
```

### 2. Ğ—Ğ°Ğ¿ÑƒÑĞº

```bash
# ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸ĞµĞ¹
chmod +x scripts/start-stack.sh
./scripts/start-stack.sh

# Ğ˜Ğ»Ğ¸ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ:
docker-compose up -d
```

### 3. Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ollama

```bash
# ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
docker-compose exec ollama-service /models/init-ollama.sh

# Ğ˜Ğ»Ğ¸ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ:
docker-compose exec ollama-service ollama pull gemini-3-flash
```

### 4. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ°

```bash
# Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ
docker-compose ps

# Ğ›Ğ¾Ğ³Ğ¸
docker-compose logs -f openclaw-gateway

# Ğ¢ĞµÑÑ‚
docker-compose exec ollama-service ollama run gemini-3-flash "Say OK"
```

---

## ğŸ“‚ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°

```
openclaw/docker/
â”œâ”€â”€ docker-compose.yml          # Stack definition
â”œâ”€â”€ Dockerfile.openclaw         # Gateway container
â”œâ”€â”€ package.json                # Gateway dependencies
â”œâ”€â”€ config/
â”‚   â””â”€â”€ openclaw.json          # Gateway configuration
â”œâ”€â”€ ollama/
â”‚   â””â”€â”€ modelfile             # gemini-3-flash model definition
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start-stack.sh        # Quick start script
â”‚   â””â”€â”€ init-ollama.sh        # Ollama initialization
â””â”€â”€ README.md                  # This file
```

---

## ğŸ³ Ğ¡ĞµÑ€Ğ²Ğ¸ÑÑ‹

### openclaw-gateway

**Node.js ÑĞµÑ€Ğ²Ğ¸Ñ** Ğ´Ğ»Ñ Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ AI Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ².

| ĞŸĞ¾Ñ€Ñ‚ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|------|----------|
| 18789 | Gateway WebSocket |
| 18790 | Health check endpoint |
| 18791 | Prometheus metrics |

### ollama-service

**AI runtime** Ğ½Ğ° Ğ±Ğ°Ğ·Ğµ Ollama.

| Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ | Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|-------------|----------|
| ĞœĞ¾Ğ´ĞµĞ»ÑŒ | gemini-3-flash |
| ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ | 131K tokens |
| ĞŸĞ¾Ñ€Ñ‚ | 11434 |
| GPU | ĞĞ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ (NVIDIA) |

---

## âš™ï¸ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ

### GPU ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ°

Ğ Ğ°ÑĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ² `docker-compose.yml`:

```yaml
ollama-service:
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
```

### Tailscale Tunnel

ĞĞ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ°:

```bash
docker-compose --profile remote up -d
```

---

## ğŸ”§ ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹

### Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ

```bash
# Ğ—Ğ°Ğ¿ÑƒÑĞº
docker-compose up -d

# ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°
docker-compose down

# Ğ ĞµÑÑ‚Ğ°Ñ€Ñ‚
docker-compose restart

# Ğ›Ğ¾Ğ³Ğ¸
docker-compose logs -f openclaw-gateway
```

### Ollama

```bash
# Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
docker-compose exec ollama-service ollama list

# Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
docker-compose exec ollama-service ollama show gemini-3-flash

# Ğ¢ĞµÑÑ‚
docker-compose exec ollama-service ollama run gemini-3-flash "Hello"
```

---

## ğŸ”— ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ

### WebSocket

```javascript
const ws = new WebSocket('ws://localhost:18789/ws');
ws.send(JSON.stringify({
  type: 'chat',
  content: 'Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ telegram-bot'
}));
```

### HTTP API

```bash
# Health check
curl http://localhost:18790/health

# Metrics
curl http://localhost:18791/metrics
```

### Ollama API

```bash
# Generate
curl http://localhost:11434/api/generate -d '{
  "model": "gemini-3-flash",
  "prompt": "Say OK"
}'
```

---

## ğŸ› Troubleshooting

### Ollama Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ÑÑ

```bash
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ»Ğ¾Ğ³Ğ¸
docker-compose logs ollama-service

# Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ start_period Ğ² healthcheck
```

### ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ÑÑ

```bash
# ĞŸĞµÑ€ĞµĞ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ
docker-compose exec ollama-service /models/init-ollama.sh

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ´Ğ¸ÑĞº
docker system df
```

### ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸

```bash
# Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ² modelfile
PARAMETER num_ctx 32768  # Ğ²Ğ¼ĞµÑÑ‚Ğ¾ 131072
```

---

## ğŸ”’ Sandbox Mode (Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾)

OpenClaw Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¸Ğ·Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ´Ğ»Ñ non-main ÑĞµÑÑĞ¸Ğ¹:

```
Main Session â†’ ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº Ñ…Ğ¾ÑÑ‚Ñƒ
Other Sessions â†’ Docker sandbox ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€
```

**ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ:**

```json
{
  "sandbox": {
    "enabled": true,
    "image": "openclaw/sandbox:latest",
    "allowlist": ["bash", "read", "write"],
    "denylist": ["browser", "canvas"]
  }
}
```

---

## ğŸ“Š ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³

```bash
# Health
curl http://localhost:18790/health

# ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
curl http://localhost:18791/metrics

# Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Docker
docker stats openclaw-gateway openclaw-ollama
```

---

## ğŸ”„ Production

### Registry

```bash
docker tag openclaw/gateway registry.example.com/openclaw:1.0.0
docker push registry.example.com/openclaw:1.0.0
```

### Swarm

```yaml
deploy:
  mode: replicated
  replicas: 1
  restart_policy:
    condition: on-failure
```

### Kubernetes

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: openclaw
spec:
  replicas: 1
  selector:
    matchLabels:
      app: openclaw
```

---

## ğŸ“š Ğ¡Ğ¼. Ğ¢Ğ°ĞºĞ¶Ğµ

- [ğŸ¦ OpenClaw README](../README.md)
- [ğŸ¯ Workspace](../workspace/README.md)
- [ğŸ¤– Agents](../workspace/AGENTS.md)

---

## ğŸ“ Ğ›Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ñ

MIT License

---

> [ğŸ  Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ](../../README.md) â†’ [ğŸ¦ OpenClaw](../README.md) â†’ [ğŸ³ Docker](#)
